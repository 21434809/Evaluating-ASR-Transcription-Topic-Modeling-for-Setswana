# -*- coding: utf-8 -*-
"""SetswanaStopWord.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1foWpHUawVYi6jssKawTOoTQUXywaJT4-
"""

# 1. Install if needed
!pip install scikit-learn pandas

# 2. Imports
import re
import pandas as pd
from sklearn.feature_extraction.text import TfidfVectorizer

files = [
    'tsn-za_web_2020_10K-sentences.txt',
    'Autshumato.MonolingualCorpus(Setswana).v2.1.tn.txt'
]

lines = [] # Use 'lines' to store individual lines first
for fn in files:
    with open(fn, 'r', encoding='utf-8') as f:
        lines.extend([line.strip() for line in f if line.strip()])
print(f'Loaded {len(lines)} combined lines from {len(files)} files.')

def clean(text):
    # remove numbering on each start of line
    text = re.sub(r'^[0-9]+\s+', '', text)
    # convert to lowercase
    text = text.lower()
    #Capatalize each start of line charaecter
    text = re.sub(r'^[a-z]', lambda x: x.group(0).upper(), text)
    # remove specail characters and punkcuation
    text = re.sub(r"[^a-zA-Z0-9\s]","",text)
    # hyphenated words in text as one
    text = re.sub(r'(\w+)-\s*(\w+)', r'\1\2', text)

    return text

docs_clean = [clean(d) for d in docs]
print("First 5 cleaned documents:")
for i in range(min(5, len(docs_clean))):
    print(docs_clean[i])

# 5. Compute TF‑IDF (Use the cleaned chunked documents)
vectorizer = TfidfVectorizer(lowercase=False,  # already cleaned
                             norm=None,        # raw tf‑idf
                             smooth_idf=True,
                             sublinear_tf=False,use_idf=True)
X = vectorizer.fit_transform(docs_clean)
feature_names = vectorizer.get_feature_names_out()

idf_scores = dict(zip(feature_names, vectorizer.idf_))

# 6. Extract low‑IDF words (highly common)
idf_thresh = pd.Series(list(idf_scores.values())).quantile(0.25)  # bottom 25%
candidates = [w for w,v in idf_scores.items() if v <= idf_thresh]
print(f'IDF threshold: {idf_thresh:.3f}, candidates: {len(candidates)} words')

# 7. Sort and output
candidates_sorted = sorted(candidates, key=lambda w: idf_scores[w])
pd.DataFrame({
    'word': candidates_sorted,
    'idf': [idf_scores[w] for w in candidates_sorted]
}).head(20)

# 8. Save to file
with open('tswana_stopwords.txt','w', encoding='utf‑8') as f:
    for w in candidates_sorted:
        f.write(w + '\n')
print('Saved stop‑word list to tswana_stopwords.txt')